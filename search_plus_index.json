{"./":{"url":"./","title":"介绍","keywords":"","body":"100 Days Of Homelab 100DaysOfHomelab是科技类YouTuber创作者Techno Tim发起的一个活动，意在用百日时间从0创建一个自己的Homelab，写Twitter促进个人进步。 参与100DaysOfHomelab活动是源于自己以前买的阿里云，腾讯云服务器2020年就到期了，之前都是用新人优惠购买，现在续费的话，老客户不如狗，续费旧服务器和买新服务器都要过千元1年，甚至3-4千一年，太贵了。于是自己淘二手服务器硬件自己组装机器放在家里，起码同样的钱，能用10年。就这样组装了第一台NAS，（配置：E3-1265L V3 / 32G内存 / 4T硬盘 * 4 组RAID10）。用了几个月，发现Homelab性价比很高，又组装了第二台服务器（配置：x79双路平台，e5-2680 v2 / 128G内存 / 1T Intel SSD固态硬盘），这台服务器装了ESXI虚拟机，专门部署大数据环境，自己用来做测试机用了。 "},"part1/homelab_network_framework.html":{"url":"part1/homelab_network_framework.html","title":"网络架构","keywords":"","body":"网络架构 "},"part1/how_to_choose_nas_system.html":{"url":"part1/how_to_choose_nas_system.html","title":"NAS选型","keywords":"","body":"NAS选型 "},"part3/install_cdh.html":{"url":"part3/install_cdh.html","title":"CDH大数据环境安装","keywords":"","body":"CDH大数据环境安装 资料 CDH6.2大数据平台安装部署 避坑 安装过程 上面这个教程比较完善了，基本上可以快速安装好CDH，由于我之前看过很多文章，下载过3个CDH的版本：CDH6.2.0，CDH6.2.1，CDH6.3.2，当时按照上面教程，跳过CDH包那步，想一次性安装CDH6.3.2，结果界面没有显示，后来先安装CDH6.3.2，然后再升级上去。 另外很多软件包已经快失传了，直接下载官方的时不可能下载到的，建议先迅雷下载，迅雷有镜像包，还可以提供资源下载。 教程中安装Httpd服务这一步，因为我自己有NAS，直接在NAS上面做webdav下载功能的，后来思考了一下，不建议大家跟教程在cdh01节点上面做，因为在后面更新或者安装其他软件的时候经常会用到，建议有条件的就在自己NAS上面建相关的下载服务，如果没有NAS条件的，建议另外建一个虚拟机或者云服务器提供服务，长期用的。 快速初始化新系统脚本 初始化要做的事情： 更换国内源 更新软件，centos7.9其实很老的了，初始化系统最好更新一下 设置时区（记得更换） 设置静态ip 关闭firewalld 设置主机名 关闭selinux 改变swap大小 (建议改成2G或者关闭，特别是有打算装doris的) 添加用户 （可选，可后面操作，特别是装spark，要添加新个人用户，不能用root进行spark-submit，会失败） 快速脚本 centos7 快速初始化脚本 一键更换国内软件源脚本 mysql版本问题 因为之前在NAS上面部署了一个mysql8和redash查询工具服务，然后手多更换了教程上面的mysql版本，从5.7缓存8，结果哭惨了，数据不能导入，要删除了，重新安装。查资料发现CM管理工具不支持mysql8。 NTP时间服务器问题 踩坑最多的地方，参考我集群时间戳不一致导致的问题及其分析和思考这个文章 NTP时间服务没有做好，后期会在CM管理系统是不是报服务不健康的错误，如果用doris，doris还要要求5秒内的时差，如果一开始没有做好，后期只能泪流满面。 "},"part3/cdh_deploy_flink.html":{"url":"part3/cdh_deploy_flink.html","title":"CDH6.2.1部署flink 1.13","keywords":"","body":"CDH6.2.1部署flink 1.13 自制Flink Parcel集成CDH（Flink1.13.2 + CDH6.2.1+Scala2.11） 测试系统安装 为了方便，我本地测试环境一般都用Oracle VM VirtualBox来安装虚拟机，加上vagrant软件，可以通过几行代码配置的方式，一键启动各种虚拟机环境，不需要自己手动一个个系统安装。 安装软件 Oracle VM VirtualBox： 最新版，官网下载就可以了 vagrant：最新版，官网下载就可以了 安装之后，还需要修改一下这2个软件的缓存目录的环境变量，不然全部缓存放到c盘，迟早有一天会爆。 参考文献： vagrant box保存路径修改 VirtualBox指定虚拟机的存储位置 vagrant 命令+配置+入门案例 - 快速创建 Centos7 官方镜像 安装虚拟机 下文以windows为例，找一个位置，创建一个空文件夹，用来存放所有的vagrant box不同虚拟机的的配置文件，然后创建我们测试用虚拟机。 # 创建存放配置的文件夹 mkdir centos7 # 初始化配置文件 vagrant init centos7 # 启动虚拟机 vagrant up 测试环境已经创建好了，账户: vagrant， 密码: vagrant 修改root用户的登录密码命令 sudo -s passwd 关于软件的使用，参考上面的文件。 注意事项 由于官方的generic/centos7镜像默认是不开启ssh，需要自己在VirtualBox软件上面，进入虚拟机先修改才能用ssh登录。 环境安装 安装JDK1.8 为了保持和CDH安装的时候那个jdk环境一样，选用一模一样的安装包，下载地址：oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm 把文件上传到/home/tools目录下 安装jdk [root@centos7 tools]# rpm -ivh oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm 注意：jdk默认会被安装到/usr/java目录中。 配置jdk环境变量，在/etc/profile文件末尾增加下面内容 [root@centos7 tools]# vi /etc/profile #..... export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera export PATH=.:$PATH:$JAVA_HOME/bin 重新加载环境变量 [root@centos7 tools]# source /etc/profile 验证jdk是否安装成功 [root@centos7 tools]# java -version java version \"1.8.0_181\" Java(TM) SE Runtime Environment (build 1.8.0_181-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode) 安装Maven Maven 下载 Maven 下载地址：http://maven.apache.org/download.cgi 下载并解压 # wget https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz # tar -xvf apache-maven-3.8.6-bin.tar.gz # sudo mv -f apache-maven-3.8.6 /usr/local/ 编辑 /etc/profile 文件 sudo vim /etc/profile，在文件末尾添加如下代码： export MAVEN_HOME=/usr/local/apache-maven-3.8.6 export PATH=${PATH}:${MAVEN_HOME}/bin 保存文件，并运行如下命令使环境变量生效： # source /etc/profile 在控制台输入如下命令，如果能看到 Maven 相关版本信息，则说明 Maven 已经安装成功： # mvn -v 安装cm_ext Cloudera提供的cm_ext工具，对生成的csd和parcel进行检验 mkdir -p ~/github/cloudera cd ~/github/cloudera # clone cm_ext git clone https://github.com/cloudera/cm_ext.git # 打包 cd cm_ext mvn package -Dmaven.test.skip=true Tips：build_parcel.sh和 build_csd.sh脚本文件里面执行jar包路径默认是~/github/cloudera/ 制作parcel parcel制作方式大致有两种，第一种是使用源生的制作方法，制作过程繁琐复杂，第二种是使用广大网友制作好的parcel制作工具，本文使用后者 先创建临时文件夹，如果跟着上文操作的可以跳过创建文件夹 mkdir -p ~/github/cloudera cd ~/github/cloudera 下载制作工具： git clone https://github.com/pkeropen/flink-parcel.git 完成后会在当前目录生成一个flink-parcel的文件，证明下载成功 修改配置文件 cd ./flink-parce vim flink-parcel.properties 进行相应修改，内容如下： #FLINK 下载地址 FLINK_URL=https://archive.apache.org/dist/flink/flink-1.13.2/flink-1.13.2-bin-scala_2.11.tgz #flink版本号 FLINK_VERSION=1.13.2 #扩展版本号 EXTENS_VERSION=BIN-SCALA_2.11 #操作系统版本，以centos为例 OS_VERSION=7 #CDH 小版本 CDH_MIN_FULL=5.2 CDH_MAX_FULL=6.3.3 #CDH大版本 CDH_MIN=5 CDH_MAX=6 保存并退出 然后进行build ./build.sh parcel 下载并打包完成后会在当前目录生成FLINK-1.13.2-BIN-SCALA_2.11_build文件 构建flink-yarn csd包 ./build.sh csd_on_yarn 执行完成后会生成FLINK_ON_YARN-1.13.2.jar 将FLINK-1.13.2-BIN-SCALA_2.11_build打包 tar -cvf ./FLINK-1.13.2-BIN-SCALA_2.11.tar ./FLINK-1.13.2-BIN-SCALA_2.11_build/ 将FLINK-1.13.2-BIN-SCALA_2.11.tar FLINK_ON_YARN-1.12.0.jar下载，这两个包就是目标包 上传到正式环境服务器(局域网yum提供的节点) 集成cm 把下载好的FLINK-1.13.2-BIN-SCALA_2.11.tar , FLINK_ON_YARN-1.12.0.jar放到自己的apache www目录下面，和安装cdh一样的，如果有NAS的可以开启webdav服务，更加方便了。 解压FLINK-1.13.2-BIN-SCALA_2.11.tar文件，得到FLINK-1.13.2-BIN-SCALA_2.11_build文件夹 # 每个节点操作一次，把parcel安装包下载到节点上 mv FLINK-1.13.2-BIN-SCALA_2.11-el7.parcel /opt/cloudera/parcel-repo/ mv FLINK-1.13.2-BIN-SCALA_2.11-el7.parcel /opt/cloudera/parcel-repo/ #登录服务器，将FLINK_ON_YARN-1.13.2.jar上传到cm主节点的/opt/cloudera/csd/目录下（目的是让cm识别） mv FLINK_ON_YARN-1.13.2.jar /opt/cloudera/csd/ 重启server和agent systemctl restart cloudera-scm-server systemctl restart cloudera-scm-agent 登录cm 在parcel配置界面添加flink的parcel源 然后进行下载→分配→解压→激活 然后可以开始安装了 可能会出现的问题 缺少jar包 缺yarn的依赖和缺少flink连接hadoop3的包还有一个hadoop-common-3.0.0-cdh6.2.1.jar commons-cli-1.4.jar flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar(所有flink节点都需要添加)，可以自行下载这两个包（联系博主也可以） mv hadoop-common-3.0.0-cdh6.2.1.jar commons-cli-1.4.jar flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar /opt/cloudera/parcels/FLINK/lib/flink/lib/ 添加完成后再重试还会报一个与Kerberos相关的错误，由于我的集群并没有开启Kerberos，所以需要到flink的配置界面中把Kerberos相关的配置删除，完后再重启就能够正常启动了。 如果启动有问题，多查看/var/log/flink/下面的日志 8081端口冲突导致启动失败 如果你和我一样是3节点的，检查一下CM后台flink的配置，把yarn.taskmanagers改成2（总节点数-1），因为默认值是1，导致多出来的那个节点要抢rest.port服务端口导致其中有一台机启动失败。 CDH flink配置设置： flink-yarn 服务环境高级配置代码段 HADOOP_USER_NAME=flink HADOOP_CONF_DIR=/etc/hadoop/conf HADOOP_HOME=/opt/cloudera/parcels/CDH HADOOP_CLASSPATH=/opt/cloudera/parcels/CDH/jars/* 资料 自制Flink Parcel集成CDH（Flink1.13.2 + CDH6.2.1+Scala2.11） CDH6.2.1集成flink1.9.0 https://www.modb.pro/db/133009 https://www.programminghunter.com/article/51042461516/ https://blog.csdn.net/spark9527/article/details/115767011 https://blog.csdn.net/u014539465/article/details/115422849 "},"part3/cdh_deploy_trino.html":{"url":"part3/cdh_deploy_trino.html","title":"CDH集成Trino (presto)","keywords":"","body":"CDH集成Trino / presto Trino是什么？ Trino的前身是PrestoSQL, 它是一个开源的分布式SQL查询引擎，它能够高效查询不同种类和各种规模的数据源，还实现了跨数据源查询。 提到PrestoSQL，就会有PrestoDB，它们都是从Presto演变而来，其中的分家原因大家感兴趣可以搜索了解一下, 文章底部我也提供了一些资料供参考。 Trino集群安装 节点规划 hostname 节点用途 bigdata-node1 coordinator bigdata-node2 Worker bigdata-node3 Worker trino版本：400 由于我安装了最新版，安装步骤还是要看一下官网文档的。 软件包安装 安装jdk17 (全部节点) 由于集群环境中已经存在低版本jdk1.8，为了避免版本更新对已有项目的影响，所以在各台服务器新增用户`presto，在新的用户中安装jdk17，并且在该新用户的环境变量配置jdk17。 新建用户presto，密码也是prestouseradd presto passwd presto trino官方推荐的jdk17版本是Azul Zulu，而且trino 400版本，对JDK版本也有要求，最低要求17.0.3，早期版本JDK8或者JDK11不会起效，最新版本JDK18或者JDK19不支持，可能有效，但是官方没有通过测试 # 找一个文件夹存放安装包 wget https://cdn.azul.com/zulu/bin/zulu17.36.13-ca-jdk17.0.4-linux_x64.tar.gz tar -zxvf zulu17.36.13-ca-jdk17.0.4-linux_x64.tar.gz -C /usr/java/ cd /usr/java mv zulu17.36.13-ca-jdk17.0.4-linux_x64 jdk17.0.4 chown -R presto:presto jdk17.0.4 修改presto用户的配置文件，增加jdk11的环境变量 vim /home/presto/.bash_profile export JAVA_HOME=/usr/java/jdk17.0.4 export JRE_HOME=$JAVA_HOME/jre export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib/rt.jar 切换到presto用户，查看jdk版本 su presto source ~/.bash_profile java -version [presto@bigdata-node1 java]$ java -version openjdk version \"17.0.4\" 2022-07-19 LTS OpenJDK Runtime Environment Zulu17.36+13-CA (build 17.0.4+8-LTS) OpenJDK 64-Bit Server VM Zulu17.36+13-CA (build 17.0.4+8-LTS, mixed mode, sharing) 安装trino (coordinator节点) 下载地址：wget https://repo1.maven.org/maven2/io/trino/trino-server/400/trino-server-400.tar.gz tar -xzvf trino-server-400.tar.gz -C /opt/ chown -R presto:presto /opt/trino-server-400 创建指定目录 # 切换presto用户 su presto # 创建日志存储目录 mkdir /opt/presto-data # 创建配置文件存放目录 mkdir /opt/trino-server-400/etc 分发到其他节点 # 由于我自己的集群机器是root免密登录的，所以用root用户分发，后面再修改权限分配 su root cd /opt/ scp -r /opt/trino-server-400 root@bigdata-node2:/opt/ scp -r /opt/trino-server-400 root@bigdata-node3:/opt/ scp -r /opt/presto-data root@bigdata-node2:/opt/ scp -r /opt/presto-data root@bigdata-node3:/opt/ coordinator配置 在bigdata-node1上配置 配置 config.properties # 编辑文件 vim /opt/trino-server-400/etc/config.properties # 新增以下内容 coordinator=true #是否复用为worker节点，默认为 false。true代表coordinator节点还有worker节点的职能 node-scheduler.include-coordinator=false # 本节点 presto 服务端口号 http-server.http.port=8089 query.max-memory=8GB query.max-memory-per-node=1GB #coordinator节点的ip和http服务端口 discovery.uri=http://bigdata-node1:8089 配置jvm.config # 编辑文件 vim /opt/trino-server-400/etc/jvm.config # 新增以下内容 -server -Xmx16G -XX:-UseBiasedLocking -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:+ExplicitGCInvokesConcurrent -XX:+ExitOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError -XX:ReservedCodeCacheSize=512M -XX:PerMethodRecompilationCutoff=10000 -XX:PerBytecodeRecompilationCutoff=10000 -Djdk.attach.allowAttachSelf=true -Djdk.nio.maxCachedBufferSize=2000000 配置node.properties # 编辑文件 vim /opt/trino-server-400/etc/node.properties # 新增以下内容 #设置集群名称 node.environment=production #节点唯一标识，同一个集群中的每个节点都不相同， 可以通过执行命令uuidgen获取, 也可以是计算机名 node.id=bigdata-node1 # 日志目录，计算临时存储目录， presto用户有读写权限 node.data-dir=/opt/presto-data/ work配置 在bigdata-node2 bigdata-node3上配置 配置 config.properties # 编辑文件 vim /opt/trino-server-400/etc/config.properties # 新增以下内容 coordinator=false #是否复用为worker节点，默认为 false。true代表coordinator节点还有worker节点的职能 node-scheduler.include-coordinator=true # 本节点 presto 服务端口号 http-server.http.port=8089 query.max-memory=8GB query.max-memory-per-node=1GB #coordinator节点的ip和http服务端口 discovery.uri=http://bigdata-node1:8089 配置jvm.config # 编辑文件 vim /opt/trino-server-400/etc/jvm.config # 新增以下内容 -server -Xmx16G -XX:-UseBiasedLocking -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:+ExplicitGCInvokesConcurrent -XX:+ExitOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError -XX:ReservedCodeCacheSize=512M -XX:PerMethodRecompilationCutoff=10000 -XX:PerBytecodeRecompilationCutoff=10000 -Djdk.attach.allowAttachSelf=true -Djdk.nio.maxCachedBufferSize=2000000 配置node.properties # 编辑文件 vim /opt/trino-server-400/etc/node.properties # 新增以下内容 #设置集群名称 node.environment=production #节点唯一标识，同一个集群中的每个节点都不相同， 可以通过执行命令uuidgen获取, 也可以是计算机名 # bigdata-node2 => bigdata-node2 # bigdata-node3 => bigdata-node3 node.id=bigdata-node2 # 日志目录，计算临时存储目录， presto用户有读写权限 node.data-dir=/opt/presto-data/ 配置日志级别（所有节点） # 默认日志级别是INFO，如果需要改DEBUG模式就增加这个文件 vim /opt/trino-server-358/etc/log.properties io.trino=DEBUG 默认的日志目录: /opt/presto-data/var/log 安装客户端（coordinator节点） 在coordinator节点，执行如下命令，安装客户端 #进入安装目录 cd /opt/trino-server-400/ #下载客户端 wget https://repo1.maven.org/maven2/io/trino/trino-cli/400/trino-cli-400-executable.jar #重命名 mv trino-cli-400-executable.jar trino-cli #赋予执行权限 chmod +x trino-cli 配置数据源（所有节点） 以mysql数据源为例 #创建并进入数据源目录 cd /opt/trino-server-400/etc/ mkdir catalog cd catalog #创建数据源文件 vim mysql.properties #添加如下内容 connector.name=mysql connection-url=jdbc:mysql://ip:3306 connection-user=user connection-password=user #设置catalog文件夹权限 chown -R presto:presto catalog 集群启动(所有节点) chown -R presto:presto /opt/trino-server-355 chown -R presto:presto /opt/presto-data 执行上面命令，主要为了防止配置的过程中，配置文件已root用户操作，在启动时presto用户权限不足 #在所有节点上执行 su presto source ~/.bash_profile # 检查java版本，确定是jdk17.0.3以上版本才有启动程序 java -version cd /opt/trino-server-400 ./bin/launcher start ./bin/launcher status Trino也提供了可视化的方式对集群状态和用户查询进行管理 管理页面：http://bigdata-node1:8089 默认用户名：admin，没有密码 trino启动脚本制作（所有节点） 为了方便管理，避免以后启动trino忘记切换用户，制作了下面的脚本，一键启动 mkdir -p /home/manager-shell vim /home/manager-shell/presto-start.sh # 添加下面的脚本 #!/bin/sh if [ `whoami` != 'presto' ];then echo '要先切换到presto用户再启动presto服务，命令:su presto' exit 1 fi echo \"当前用户 = ${USER}\" source ~/.bash_profile java -version cd /opt/trino-server-400 ./bin/launcher start ./bin/launcher status 执行命令的方式： source ./presto-start.sh 或者 . ./presto-start.sh 资料 Presto(Trino)从安装到使用 CDH集成Trino(PrestoSQL) 从 0 到 1 学习 Presto，这一篇就够了 认识Trino trino权限验证开启https 初识Presto(Trino)/) "},"part3/cdh_upgrade_spark2.4.6.html":{"url":"part3/cdh_upgrade_spark2.4.6.html","title":"CDH6.2.1 升级 spark2.4.6版本","keywords":"","body":"CDH6.2.1 升级 spark2.4.6版本 背景 由于 CDH6.3.2 以上，已不开源。常用组件只能自编译升级，比如 Spark 。这次决定升级spark，但是不选择3.x版本主要是因为公司用的最新版本也就2.4.4，而且升级最新版的话，其他附带的服务也要跟着升级，动作太大，不适宜已经在生产环境部署。 编译环境 名称 版本 备注 jdk 1.8.0_181 oracle的 Maven 3.8.4+ 直接安装最新版就可以了 Centos 7.9 我建议本地电脑装虚拟机编译，cpu和内存都够大，不要再线上环境或者云服务器上编译。编译环境部署可以参考我CDH6.2.1部署flink 1.13文章里面的环境部署内容 下载软件 下载需要编译的软件，我存放目录是/home/vagrant/tools wget https://archive.apache.org/dist/spark/spark-2.4.6/spark-2.4.6.tgz # 创建临时编译用的目录 mkdir spark # 解压源代码 tar -zxvf spark-2.4.6.tgz -C spark 编译spark 修改make-distribution.sh # 进入源代码目录 cd spark/spark-2.4.6 #修改版本号为固定版本,避免编译时脚本自动获取 vim dev/make-distribution.sh 找到下面那段代码，并注释掉，然后添加新代码 VERSION=$(\"$MVN\" help:evaluate -Dexpression=project.version $@ 2>/dev/null\\ | grep -v \"INFO\"\\ | grep -v \"WARNING\"\\ | tail -n 1) SCALA_VERSION=$(\"$MVN\" help:evaluate -Dexpression=scala.binary.version $@ 2>/dev/null\\ | grep -v \"INFO\"\\ | grep -v \"WARNING\"\\ | tail -n 1) SPARK_HADOOP_VERSION=$(\"$MVN\" help:evaluate -Dexpression=hadoop.version $@ 2>/dev/null\\ | grep -v \"INFO\"\\ | grep -v \"WARNING\"\\ | tail -n 1) SPARK_HIVE=$(\"$MVN\" help:evaluate -Dexpression=project.activeProfiles -pl sql/hive $@ 2>/dev/null\\ | grep -v \"INFO\"\\ | grep -v \"WARNING\"\\ | fgrep --count \"hive\";\\ # Reset exit status to 0, otherwise the script stops here if the last grep finds nothing\\ # because we use \"set -o pipefail\" echo -n) 最终修改效果 #VERSION=$(\"$MVN\" help:evaluate -Dexpression=project.version $@ 2>/dev/null\\ # | grep -v \"INFO\"\\ # | grep -v \"WARNING\"\\ # | tail -n 1) #SCALA_VERSION=$(\"$MVN\" help:evaluate -Dexpression=scala.binary.version $@ 2>/dev/null\\ # | grep -v \"INFO\"\\ # | grep -v \"WARNING\"\\ # | tail -n 1) #SPARK_HADOOP_VERSION=$(\"$MVN\" help:evaluate -Dexpression=hadoop.version $@ 2>/dev/null\\ # | grep -v \"INFO\"\\ # | grep -v \"WARNING\"\\ # | tail -n 1) #SPARK_HIVE=$(\"$MVN\" help:evaluate -Dexpression=project.activeProfiles -pl sql/hive $@ 2>/dev/null\\ # | grep -v \"INFO\"\\ # | grep -v \"WARNING\"\\ # | fgrep --count \"hive\";\\ # # Reset exit status to 0, otherwise the script stops here if the last grep finds nothing\\ # # because we use \"set -o pipefail\" # echo -n) # 添加下面代码 VERSION=2.4.6 SCALA_VERSION=2.11 SPARK_HADOOP_VERSION=3.0.0-cdh6.2.1 SPARK_HIVE=1 # 支持spark on hive 说明： VERSION：spark的版本号，修改成你当前下载的版本 SCALA_VERSION：scala版本，2.4.x系列可用版本是2.11或者2.12，具体版本查一下资料 SPARK_HADOOP_VERSION：hadoop的版本，看一下你自己当前的版本，我用的是cdh，所以这个版本 修改maven编译内存，加快速度 #找到下面的代码 export MAVEN_OPTS=\"${MAVEN_OPTS:--Xmx2g -XX:ReservedCodeCacheSize=512m}\" 然后修改成自己可以接受的内存 export MAVEN_OPTS=\"${MAVEN_OPTS:--Xmx8g -XX:ReservedCodeCacheSize=2g}\" 修改pox.xml 修改pox.xml文件 （在源代码的根目录），增加 cloudera maven 仓库 在 repositories 标签下，新增 cloudera https://repository.cloudera.com/artifactory/cloudera-repos true false 如果你没有上外网的基础，需要多增加下面这个国内仓库 aliyun https://maven.aliyun.com/nexus/content/groups/public true false 开始编译 ./dev/make-distribution.sh \\ --name hadoop3.0.0-cdh6.2.1 --tgz -Pyarn -Phadoop-3.0 \\ -Phive-thriftserver -Dhadoop.version=3.0.0-cdh6.2.1 -DskipTests -X -X这个参数是debug模式，会输出更多日志，如果不想看的话，把这个参数删除； -Dhadoop.version这个参数是对应你hadoop的版本 经过1小时漫长等待，终于编译好了，文件spark-2.4.6-bin-hadoop3.0.0-cdh6.2.1.tgz 部署到集群 上传编译好的文件到要部署 spark3 的客户端机器上 tar -zxvf spark-2.4.6-bin-hadoop3.0.0-cdh6.2.1.tgz -C /opt/cloudera/parcels/CDH/lib cd /opt/cloudera/parcels/CDH/lib mv spark-2.4.6-bin-hadoop3.0.0-cdh6.2.1/ spark2 添加CDH环境配置 链接hadoop/hive相关的配置文件到 conf目录下 cd spark2 ln -s /etc/hive/conf/hdfs-site.xml hdfs-site.xml ln -s /etc/hive/conf/mapred-site.xml mapred-site.xml ln -s /etc/hive/conf/yarn-site.xml yarn-site.xml ln -s /etc/hive/conf/core-site.xml core-site.xml ln -s /etc/hive/conf/hive-env.sh hive-env.sh ln -s /etc/hive/conf/hive-site.xml hive-site.xml 添加spark配置 cp /etc/spark/conf/spark-env.sh /opt/cloudera/parcels/CDH/lib/spark2/conf chmod +x /opt/cloudera/parcels/CDH/lib/spark2/conf/spark-env.sh #修改 spark-env.sh vim /opt/cloudera/parcels/CDH/lib/spark2/conf/spark-env.sh export SPARK_HOME=/opt/cloudera/parcels/CDH/lib/spark3 cp /etc/spark/conf/log4j2.properties /opt/cloudera/parcels/CDH/lib/spark2/conf cp /etc/spark/conf/spark-defaults.conf /opt/cloudera/parcels/CDH/lib/spark2/conf # 修改spark-defaults.conf，下面写的修改，其他的保持不变 # 修改结果 spark.yarn.jars=local:/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark2/jars/*,local:/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark2/hive/* #spark.extraListeners=com.cloudera.spark.lineage.NavigatorAppListener #spark.sql.queryExecutionListeners=com.cloudera.spark.lineage.NavigatorQueryListener 创建 spark-sql vim /opt/cloudera/parcels/CDH/bin/spark-sql #!/bin/bash export HADOOP_CONF_DIR=/etc/hadoop/conf export YARN_CONF_DIR=/etc/hadoop/conf SOURCE=\"${BASH_SOURCE[0]}\" BIN_DIR=\"$( dirname \"$SOURCE\" )\" while [ -h \"$SOURCE\" ] do SOURCE=\"$(readlink \"$SOURCE\")\" [[ $SOURCE != /* ]] && SOURCE=\"$BIN_DIR/$SOURCE\" BIN_DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\" done BIN_DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\" LIB_DIR=$BIN_DIR/../lib export HADOOP_HOME=$LIB_DIR/hadoop # Autodetect JAVA_HOME if not defined . $LIB_DIR/bigtop-utils/bigtop-detect-javahome exec $LIB_DIR/spark2/bin/spark-submit --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver \"$@\" 配置 spark-sql 快捷方式 chmod +x /opt/cloudera/parcels/CDH/bin/spark-sql alternatives --install /usr/bin/spark-sql spark-sql /opt/cloudera/parcels/CDH/bin/spark-sql 1 创建 spark3-submit vim /opt/cloudera/parcels/CDH/bin/spark2-submit #!/bin/bash # Reference: http://stackoverflow.com/questions/59895/can-a-bash-script-tell-what-directory-its-stored-in SOURCE=\"${BASH_SOURCE[0]}\" BIN_DIR=\"$( dirname \"$SOURCE\" )\" while [ -h \"$SOURCE\" ] do SOURCE=\"$(readlink \"$SOURCE\")\" [[ $SOURCE != /* ]] && SOURCE=\"$DIR/$SOURCE\" BIN_DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\" done BIN_DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\" LIB_DIR=$BIN_DIR/../lib export HADOOP_HOME=$LIB_DIR/hadoop # Autodetect JAVA_HOME if not defined . $LIB_DIR/bigtop-utils/bigtop-detect-javahome # disable randomized hash for string in Python 3.3+ export PYTHONHASHSEED=0 exec $LIB_DIR/spark2/bin/spark-submit \"$@\" 配置 spark2-submit 快捷方式 chmod +x /opt/cloudera/parcels/CDH/bin/spark3-submit alternatives --install /usr/bin/spark2-submit spark2-submit /opt/cloudera/parcels/CDH/bin/spark2-submit 1 分发spark软件包 scp -r spark2 root@bigdata-node2:/opt/cloudera/parcels/CDH/lib/ scp -r spark2 root@bigdata-node3:/opt/cloudera/parcels/CDH/lib/ 测试 spark2-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 1 /opt/cloudera/parcels/CDH/lib/spark2/examples/jars/spark-examples*.jar 10 资料 spark2.4.4-CDH6.3.0编译 Spark SQL 3.0.1 与 CDH Hive 2.1.1结合 CDH6.3.2 升级 Spark3.3.0 版本 错误问题修改 ：https://blog.csdn.net/qq_26442553/article/details/126028533 https://developer.aliyun.com/article/232648 https://codeantenna.com/a/Uuz3Z8pDkc https://hijiazz.gitee.io/apache-spark247-hadoop31-build/ https://blog.csdn.net/weixin_44641024/article/details/102624086 https://blog.csdn.net/qq_43591172/article/details/126575084 cdh6.x 集成spark-sql https://blog.csdn.net/qq_26502245/article/details/120355741 "},"part3/cdh_install_sparksql.html":{"url":"part3/cdh_install_sparksql.html","title":"CDH6.3.2 集成 spark-sql","keywords":"","body":"CDH6.3.2 集成 spark-sql 资料 CDH6.3.2添加spark-sql "},"part3/install_ambari_2.7.3.html":{"url":"part3/install_ambari_2.7.3.html","title":"Ambari 2.7.3 安装","keywords":"","body":"Ambari 2.7.3 安装 主要参考资料： Ambari 2.7.3 离线安装手册 "},"part3/cdh_install_livy.html":{"url":"part3/cdh_install_livy.html","title":"CDH6集成Livy服务 HUE支持sparksql查询","keywords":"","body":"CDH6集成Livy服务 HUE支持sparksql查询 资料 CDH6集成Livy服务 CDH使用CM安装整合livy和zepplin(已攻略) Apache Livy 安装部署使用示例 编译注意 超级注意：要编译livy的0.7.0以上版本，如果编译0.5.0版本，会出现使用spark-sql的时候，decimal数据类型出错，是scale版本不支持导致的。可以查看官网更新日志，是因为0.7.0以上才支持spark 2.4.x。 教程里面是先编译，后解压parcel文件，修改meta/parcel.json， 其实可以一开始就编辑livy-parcel-src/meta/parcel.json里面，添加添加livy用户和组，然后再编译就不需要解压，后编辑。 cdh 6.3.2版本重启 systemctl restart cloudera-scm-server 重启是上面的命令，不是在后台界面操作 "},"part3/linux_system/ntpd.html":{"url":"part3/linux_system/ntpd.html","title":"集群时间戳不一致导致的问题及其分析和思考","keywords":"","body":"集群时间戳不一致导致的问题及其分析和思考 ntp 对Linux而言，可以使用ntp来实现集群的时间同步。 同步时间，可以使用ntpdate命令，也可以使用ntpd服务。 ntpdate 使用ntpdate比较简单。格式如下： $ ntpdate [-nv] [NTP IP/hostname] $ ntpdate 192.168.0.1 $ ntpdate time.ntp.org ntpdate只是强制将系统时间设置为ntp服务器时间。如果机器cpu tick有问题，这种同步治标不治本。此时，一般配合cron任务来定期同步。例如： 3 * * * * /usr/sbin/ntpdate 172.17.1.1 ntpd 使用ntpd服务，要好于使用ntpdate+cron。 ntpdate同步时间，会造成时间的跳跃，对一些依赖时间的程序和服务会造成影响，比如sleep，timer等。 ntpd服务可以在修正时间的同时，修正cpu tick。 理想的做法为，在开机的时候，使用ntpdate强制同步时间，在其他时候使用ntpd服务来同步时间。 需要注意的是，ntpd有一个自我保护设置: 如果本机时间与源时间相差太大, 则ntpd不运行。所以新设置的时间服务器一定要先利用ntpdate命令获取初始时间, 然后启动ntpd服务。 关于ntpd的使用，网上已经有很多资料了，这里就不做过多的介绍了。 ntpstat ntpstat用于显示网络时间的同步状态。ntpstat会给出本地计算机上运行的ntpd的同步状态。如果本地系统与参考时间源同步，则ntpstat会给出近似的时间精度。 $ ntpstat synchronised to NTP server (192.168.0.1) at stratum 3 time correct to within 43 ms polling server every 1024 s 问题引申 虽然可以利用ntp来同步集群时间，但是有一个问题是值的思考的：如何在集群时钟不同的情况下，解决时间戳不一致带来的问题一节中描述的问题。 系统在架构上要做何种优化，才能避免业务对集群时钟同步的依赖？而这种优化所带来的系统架构的复杂度和成本又将如何？ 资料 集群时间戳不一致导致的问题及其分析和思考 那些年我们忽略的集群时钟不同步问题 "},"part3/how_to_build_bigdata_analysis_platform.html":{"url":"part3/how_to_build_bigdata_analysis_platform.html","title":"如何整合复杂技术打造数据分析平台？","keywords":"","body":"如何整合复杂技术打造数据分析平台？ "},"part3/how_to_choose_bi_system.html":{"url":"part3/how_to_choose_bi_system.html","title":"BI系统选型","keywords":"","body":"BI系统选型 "},"part3/bigdata_technology_stack.html":{"url":"part3/bigdata_technology_stack.html","title":"纷繁复杂的大数据技术栈清单","keywords":"","body":"纷繁复杂的大数据技术栈清单 关系型数据库管理系统 MySQL 世界上最流行的开源数据库。 PostgreSQL 世界上最先进的开源数据库。 Oracle Database - 对象关系数据库管理系统。 Teradata - 高性能 MPP 数据仓库平台。 框架 Bistro - 用于批处理和流分析的通用数据处理引擎。它基于一种新的数据模型，该模型通过函数来表示数据，并通过列操作来处理数据，而不仅仅使用 MapReduce 或 SQL 等传统方法来设置操作。 IBM Streams - 分布式处理和实时分析平台。可以和大数据生态系统中的许多流行技术 (Kafka、HDFS、Spark等) 集成 Apache Hadoop -分布式处理框架。集成了 MapReduce(并行处理)、YARN(作业调度)和HDFS(分布式文件系统)。 Tigon - 高吞吐的实时流处理框架。 Pachyderm - Pachyderm 是一个基于 Docker 和 Kubernetes 的数据存储平台，可以用在重复的数据处理和分析场景。 Polyaxon - 一个可复制、可扩展的机器学习和深度学习平台。 分布式编程 AddThis Hydra - 分布式数据处理和存储系统，最初由 AddThis 开发。 AMPLab SIMR - 在 Hadoop MapReduce v1 上运行 Spark。 Apache APEX - 用于大数据流和批处理的统一企业平台。 Apache Beam - 用于定义和执行数据处理工作流的统一模型和一组特定于语言的sdk。 Apache Crunch - 一个简单的Java API，用于处理 Join 和数据聚合之类的任务，这些任务在普通 MapReduce 上实现起来很繁琐。 Apache DataFu - 由 LinkedIn 为 Hadoop 和 Pig 开发的用户定义函数的集合。 Apache Flink - 分布式处理引擎框架，用于在无界和有界数据流上进行有状态计算。 Apache Gearpump -基于 Akka 的实时大数据流引擎。 Apache Gora - 内存数据模型和持久性框架。 Apache Hama - BSP(Bulk Synchronous Parallel)计算框架。 Apache MapReduce -在集群上使用并行分布式算法处理大型数据集的编程模型。 Apache Pig - 用于表达 Hadoop 数据分析程序的高级语言。 Apache REEF - 用来简化和统一低层大数据系统的保留性评估执行框架 Apache S4 - 一个常规用途的、分布式的、可伸缩的、容错的、可插入式的平台，主要用于处理连续的数据流 Apache Spark - 快速、通用的大规模数据处理引擎 Apache Spark Streaming - 实时流处理引擎，属于 Spark 的一部分. Apache Storm - Twitter 开发的，可在 YARN 上进行流处理的框架。 Apache Samza -基于 Kafka 和 YARN 的流处理的框架 Apache Tez - 基于 YARN 的，可执行复杂 DAG (有向无环图)任务的应用程序框架。 Apache Twill - YARN 上的抽象，减少了开发分布式应用程序的复杂性。 Baidu Bigflow - 一个允许编写分布式计算程序的接口，它提供了许多简单、灵活、强大的 API 来轻松处理任何规模的数据。 Cascalog - 数据处理和查询库。 Cheetah - MapReduce 之上的高性能，用户自定义数据仓库。 Concurrent Cascading - Hadoop 上的数据管理/分析框架。 Damballa Parkour - 为 Clojure 开发的 MapReduce 库。 Datasalt Pangool - 可替代 MapReduce 范式. DataTorrent StrAM -实时计算引擎，旨在以一种尽可能畅通的方式支持分布式、异步、实时的内存大数据计算，同时最小化开销和对性能的影响。 Facebook Corona - Hadoop 的增强，可以消除单点故障。 Facebook Peregrine - Map Reduce 框架. Facebook Scuba - 分布式内存数据存储。 Google Dataflow - 创建数据管道来帮助我们摄取、转换和分析数据。 Google MapReduce - map reduce 框架. Google MillWheel - 容错流处理框架。 IBM Streams - 用于分布式处理和实时分析的平台。 提供开箱即用的高级分析工具包，如地理空间，时间序列等。 JAQL - 声明式编程语言，用于处理结构化、半结构化和非结构化数据。 Kite - 一组库、工具、示例和文档，重点在于简化在 Hadoop 生态系统之上构建系统的过程。 Metamarkets Druid - 用于实时分析大型数据集的框架。 Netflix PigPen - 是 Clojure 语音的 Map-Reduce，可以编译到 Apache Pig 或者 Cascading 中 Nokia Disco - 诺基亚开发的 MapReduce 框架。 Onyx - 云的分布式计算。 Pinterest Pinlater - 异步作业执行系统。 Pydoop - 用 Python 编写，并采用 MapReduce 和 HDFS 技术对 Hadoop 进行扩展的 API。 Ray - 用于构建和运行分布式应用程序的快速而简单的框架。 Rackerlabs Blueflood - 多租户分布式度量处理系统 Skale - NodeJS 上的高性能分布式数据处理框架。 Stratosphere - 通用集群计算框架。 Streamdrill - streamdrill 在计算不同时间窗口上的事件流活动非常有用，并找出最活跃的时间窗口。 streamsx.topology - 用于在 Java，Python 或 Scala 中构建 IBM Streams 应用程序的库。 Tuktu - 易于使用的批处理和流式计算平台，可以使用 Scala，Akka 和 Play 构建！ Twitter Heron - 由 Twitter 开发的一个实时、分布式、容错的流处理引擎，主要用于代替 Storm。 Twitter Scalding - 用于 Map Reduce 作业的 Scala 库，基于 Cascading 构建。 Twitter Summingbird - Summingbird 是一个类库，它允许我们编写看起来像原生 Scala 或 Java 集合转换的 MapReduce 程序，并在许多着名的分布式 MapReduce 平台上执行，包括 Storm 和 Scalding，由 Twitter 开发。 Twitter TSAR - Twitter 开发的时间序列聚合器 Wallaroo - 超快弹性数据处理引擎，可以使有状态、分析、流处理和事件驱动的 AI 应用程序能够快速投入生产，而无需考虑规模。它为开发人员提供了几种语言的 api 来实现他们的自定义业务逻辑。 分布式文件系统 Ambry - 分布式对象存储，支持存储数万亿个小的不可变对象或者数十亿个大对象。 Apache HDFS - 提供对应用程序数据的高吞吐量访问的分布式文件系统。 Apache Kudu - Hadoop 的存储层可实现对数据的快速分析。 BeeGFS - 之前称为 FhGFS，是一种并行分布式文件系统。 Ceph Filesystem - 一个支持POSIX接口的文件系统 Disco DDFS - 分布式文件系统。 Facebook Haystack - 对象存储系统。 Google Colossus - 分布式文件系统 (GFS2). Google GFS - 分布式文件系统。 Google Megastore - 可扩展、高可用的存储。 GridGain - GGFS, Hadoop 兼容的内存文件系统。 Lustre file system - 高性能分布式文件系统。 Microsoft Azure Data Lake Store - Azure 上兼容 HDFS 的存储 Quantcast File System QFS - 开源分布式文件系统。 Red Hat GlusterFS - 横向扩展网络附加的存储文件系统。 Seaweed-FS -简单且高度可伸缩的分布式文件系统。 Alluxio - 开源的基于内存的分布式存储系统。 Tahoe-LAFS - 去中心化的云存储系统。 Baidu File System - 分布式文件系统。 分布式索引 Pilosa 开源的分布式位图索引，极大地加速了跨多个大规模数据集的查询。 文档数据模型 Actian Versant - 面向对象的商业数据库管理系统。 Crate Data - 是一个开源的大规模可扩展数据存储，它不需要任何管理。 Facebook Apollo - Facebook 的类似于 Paxos 的 NoSQL 数据库。 jumboDB - 基于 Hadoop 的面向文档的数据存储。 LinkedIn Espresso - 可水平扩展的面向文档 NoSQL 数据存储。 MarkLogic - 模式无关的企业 NoSQL 数据库技术。 Microsoft Azure DocumentDB - NoSQL 云数据库服务，支持 MongoDB 协议 MongoDB - 面向文档的数据库系统。 RavenDB - 支持事务的开源文档数据库。 RethinkDB - 支持表 join 和 group by 等查询的文档数据库。 Key-value 数据模型 Aerospike - 一个分布式，高可用的 K-V 类型的 NOSQL 数据库。提供类似传统数据库的ACID操作。 Amazon DynamoDB - 分布式 key/value 存储, Dynamo 论文的实现。 Badger - 一个快速、简单、高效和持久的键值存储，是用 Go 编写。 Bolt - 可在 Go 语言中使用的嵌入式键值数据库. BTDB - .Net 中的 Key Value 数据库，包含 Object DB Layer, RPC, dynamic IL 等等。 BuntDB - Go 语言的一个快速，可嵌入，基于内存的键/值数据库，支持自定义索引和地理空间。 Edis - 协议兼容 Redis 的数据库，可替代 Redis。 ElephantDB - 专门用于从 Hadoop 导出数据的分布式数据库。 EventStore - 分布式时间序列数据库。 GridDB - 一款高度可扩展的 NoSQL 数据库，非常适用于物联网和大数据领域，还具有高可靠性和高性能这些特性。 HyperDex - 可扩展的下一代键值和文档存储，具有多种功能，包括一致性，容错性和高性能。 Ignite - 分布式内存网格数据库，具有可持久化，分布式事务，分布式计算等特点，此外还支持丰富的键值存储以及SQL语法。 LinkedIn Krati - 一个简单的持久化数据存储，具有非常低的延迟和高吞吐量。 Linkedin Voldemort - 分布式 key/value 存储系统。 Oracle NoSQL Database - Oracle 公司开发的分布式 key/value 存储系统。. Redis -一个开源(BSD许可)的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 Riak - 去中心化的数据库存储。 Storehaus -Twitter 开发的用于异步 key/value 存储的类库。 SummitDB - 基于内存的 NoSQL 键/值数据库，具有磁盘持久性，并支持 Raft 一致性算法。 Tarantool - 一个高效的 NoSQL 数据库和一个 Lua 应用服务器。 TiKV - 一个基于 Rust 的分布式键值数据库，并受谷歌 Spanner 和 HBase 的启发。 Tile38 - 具有空间索引和实时地理围栏的地理位置数据库。支持各种对象类型，包括纬度/经度点，边界框，XYZ切片，Geohashes和GeoJSON TreodeDB - key-value 存储，支持数据副本、分片以及提供原子多行写。 图数据模型 AgensGraph - 基于 PostgreSQL 的新一代多模型图数据库。 Apache Giraph - 一个可伸缩的分布式迭代图处理系统， 基于 Hadoop 平台，灵感来自 BSP (bulk synchronous parallel) 和 Google 的 Pregel。 Apache Spark Bagel - Bagel 是谷歌 Pregel 图处理框架的 Spark 实现，支持基本的图形计算、组合器（combiners）和聚合器（aggregators）。目前已经被 GraphX 替代，在 Spark 2.0.0 版本已经被移除。 ArangoDB - 多模型分布式数据库。 DGraph - 一个可伸缩的、分布式的、低延迟的、高吞吐量的图数据库，旨在提供谷歌生产级别的规模和吞吐量，具有足够低的延迟，可以在 TB 级的结构化数据上为实时用户查询提供服务。 EliasDB - 一个轻量级的基于图的数据库，不需要任何第三方库。 Facebook TAO - TAO 是 facebook 广泛使用的分布式数据存储，用于存储和服务社交图。 GCHQ Gaffer - Gaffer 是 GCHQ（英国政府通讯总部）于2015年12月14日在 GitHub 上公布的第一个开源项目，Gaffer 是个大规模图形数据库，可以方便存储大规模图的框架，节点和边界有数据统计，比如计数，直方图和草图。这些统计数据是时间窗口的节点和边界属性，可以根据时间动态更新。 Google Cayley - 开源的图数据库。 Google Pregel - 图处理框架。 GraphLab PowerGraph - 包含 C++ 实现的 GraphLab API以及一组基于GraphLab API 构建的高性能机器学习和数据挖掘工具包。 GraphX - 一个分布式图处理框架，它是基于 Spark 平台提供对图计算和图挖掘简洁易用的而丰富的接口，极大的方便了对分布式图处理的需求。 Gremlin - 图遍历语言。 Infovore - 一个 map/reduce 框架，用来处理大量的 RDF 数据集，注入 Freebase 和 DBpedia，基于 Hadoop 构建。 Intel GraphBuilder - 基于 Hadoop 构造的大型图工具。 JanusGraph - 开源分布式图形数据库，后端存储可以选择多种组件包括 Bigtable、HBase、Cassandra等，同时索引后端也可以选择很多种，包括 Elasticsearch、Solr、Lucene 等。 MapGraph - 一个高级的 API 用于快速开发基于 GPU 的高性能图形分析应用。 Microsoft Graph Engine - 一个基于内存的分布式大规模图数据处理引擎，能够帮助用户更方便地构建实时查询应用和高吞吐量离线分析平台。在此之前，它在学术界更广为人之的名称是 Trinity。 Neo4j - 一个高性能的 NOSQL图数据库，完全由 Java 实现。 OrientDB - 文档图形数据库。 Phoebus - 大型图处理框架。 Titan - 建立在 Cassandra 之上的分布式图数据库。 Twitter FlockDB - 分布式图数据库。 NodeXL - Microsoft® Excel® 2007, 2010, 2013 and 2016 免费开源的模板，可以很容易的探索网络图。 列式数据库 注意 请读一下 Key-Map Data Model 章节的说明。 Columnar Storage - 解释什么是列式存储，以及我们什么时候需要它。 Actian Vector - 面向列的分析数据库。 C-Store - 面向列的 DBMS. ClickHouse - 一个开源的列式数据库（DBMS），主要用于在线分析处理查询（OLAP）。 EventQL - 为大规模事件收集和分析而构建的分布式、面向列的数据库。 MonetDB - 列式存储数据库。 Parquet - 灵感来自于2010年 Google 发表的 Dremel 论文，是一种列式存储格式，与语言、平台无关，并且不需要和任何一种数据处理框架绑定。 Pivotal Greenplum - 为特定目的而构建的专用分析数据仓库，它提供了一个列式存储引擎和一个传统的基于行的引擎。 Vertica - 设计用于管理大量快速增长的数据，提供非常快的查询性能。 SQream DB - 以色列大数据公司开发的跑在 GPU 上的大数据数据库，设计用于分析和数据仓库，使用 ANSI-92 SQL，适用于10TB到1PB的数据集。 Google BigQuery - Google 推出的一项 Web 服务，该服务让开发者可以使用 Google 的架构来运行 SQL 语句对超级大的数据库进行操作。 Amazon Redshift - 一个支持 SQL 查询的、快速、可扩展的列式存储数据库，它支持 PB 级的数量查询，是适用于企业级的数据仓库。 IndexR - 一个开源的大数据存储格式，于 2017 年 1 月初正式开源，旨在通过添加索引、优化编码方式、提高 IO 效率等各种优化方式来提高计算层和存储层的数据交换效率，从而提升整体性能。 LocustDB - 一个大规模并行且高性能的分析数据库 (analytics database)，可快速处理你的所有数据，目前处于实验性阶段。 NewSQL 数据库 Actian Ingres - 商业支持，开源 SQL 关系数据库管理系统。 ActorDB - 分布式的 SQL 数据库，可实现可伸缩的 K/V 存储系统。ActorDB 基于 Actor 计算模型，与传统的集中式数据库不同，ActorDB 由任意数量的被成为 actor 的独立和并发 SQL 数据库组成。 Amazon RedShift -基于 PostgreSQL 的数据仓库服务。 BayesDB - 一个贝叶斯数据库，内建贝叶斯查询语言 BQL，用户无需统计方面知识即可解决一些基本的科学数据问题 Bedrock - 构建在 SQLite 之上的简单、模块化、网络化、分布式事务层。 CitusDB - 通过分片和副本扩展 PostgreSQL。 Cockroach - 可伸缩、地理复制、事务性数据存储。 Comdb2 - 一个基于乐观并发控制技术的集群 RDBMS。 Datomic - 分布式数据库旨在支持可伸缩、灵活和智能的应用程序。 FoundationDB - 分布式数据库，受 F1 启发。 Google F1 - 构建在 Spanner 之上的分布式 SQL 数据库。 Google Spanner - Google的全球级的分布式数据库，具有可扩展，多版本，全球分布式、同步复制等特性。 H-Store - 一个实验性的数据库管理系统。它专为驻线交易处理应用程序而设计。 Haeinsa - Haeinsa 是 HBase 可线性扩展的多行，多表事务库。使用两阶段锁定和乐观并发控制来实现事务。 事务的隔离级别是可序列化的。基于 Percolator 实现。 HandlerSocket - MySQL/MariaDB 的 NoSQL 插件。 InfiniSQL - 无限扩展的 RDBMS. Map-D - GPU 内存数据库，大数据分析可视化平台. MemSQL - 一款内存数据库，它通过将数据存在内存中，将 SQL 语句预编译为 C++ 而获得极速执行效率。 NuoDB - 符合 SQL/ACID 的分布式数据库。 Oracle TimesTen in-Memory Database - 基于内存的关系数据库管理系统，具有持久性和可恢复性。 Pivotal GemFire XD - 低延迟、基于内存、分布式 SQL 数据存储。为内存表数据提供 SQL 接口，可在 HDFS 中持久存储。 SAP HANA - 基于内存、面向列、关系数据库管理系统。 SenseiDB - 分布式、实时、半结构化的数据库。 Sky - 用于灵活、高性能的行为数据分析的数据库。 SymmetricDS - 用于文件和数据库同步的开源软件。 TiDB - 一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。受 Google F1 启发。 VoltDB - 声称是最快的内存数据库. 时间序列数据库 Axibase Time Series Database - 基于 HBase 的时间序列数据库，内置可视化、规则引擎和 SQL 支持。 Chronix - 一种时间序列存储器，用于存储高度压缩的时间序列，并支持快速访问数据。 Cube - 使用 MongoDB 来存储时间序列数据。 Heroic - 基于 Cassandra 和 Elasticsearch 的可扩展时间序列数据库。 InfluxDB - 分布式时间序列数据库。 IronDB - 可扩展、通用时间序列数据库。 Kairosdb - 和 OpenTSDB 类似，但是构建在 Cassandra 之上。 M3DB - 一个分布式时间序列数据库，可用于长期存储实时指标。 Newts -基于 Apache Cassandra 的时间序列数据库。 OpenTSDB -构建在 HBase 之上的分布式时间序列数据库。 Prometheus - 时间序列数据库和服务监控系统。 Beringei - Facebook 的内存时间序列数据库。 TrailDB - 用于存储和查询一系列事件的有效工具。 Druid MetaMarket 公司研发，专为海量数据集上的做高性能 OLAP (OnLine Analysis Processing)而设计的数据存储和分析系统 Riak-TS Riak TS 是唯一专为物联网和时间序列数据优化的企业级 NoSQL 时间序列数据库。 Akumuli 一个数值型时间序列数据库，可以存储、处理时序列数据 Rhombus Cassandra的时间序列对象存储。 Dalmatiner DB 快速分布式度量数据库 Blueflood 一种用于摄取和处理时间序列数据的分布式系统。 Timely 是一个时间序列数据库应用程序，它提供了基于 Accumulo 和 Grafana 的对时间序列数据的安全访问。 SiriDB 具有集群功能的高扩展性、健壮性和快速的开源时间序列数据库。 Thanos - Thanos 是一组组件，可以使用多个 Prometheus 部署创建具有无限存储容量的高可用度量系统。 VictoriaMetrics - 与 Prometheus 兼容的快速，可扩展的开源 TSDB，包括单节点和群集版本。 类 SQL 处理系统 Actian SQL for Hadoop - 高性能交互式 SQL，可以利用它访问 Hadoop 上的数据。 Apache Drill - 一个低延迟的分布式海量数据交互式查询引擎，使用 ANSI SQL 兼容语法，本质上是一个分布式的 MPP 查询层。目的在于支持更广泛的数据源，数据格式，以及查询语言。受 Google的Dremel 启发。 Apache HCatalog - Hadoop的表存储管理工具。 Apache Hive - 基于 Hadoop 的一个数据仓库工具，可以将结构化数据文件映射为一张数据库表，并提供类 SQL 查询功能. Apache Calcite - 一款开源 SQL 解析工具, 可以将各种 SQL 语句解析成抽象语法术AST(Abstract Syntax Tree), 之后通过操作 AST 就可以把 SQL 中所要表达的算法与关系体现在具体代码之中。 Apache Phoenix - 构建在 HBase 之上的关系型数据库层，可以对 HBase 中的数据进行低延迟访问。 Aster Database - 类 SQL 分析处理。 Cloudera Impala - 实时交互 SQL 大数据查询工具，受 Dremel 启发。 Concurrent Lingual - Cascading 上的 SQL 查询语言。 Datasalt Splout SQL - 针对大数据集的完整 SQL 查询引擎。 Facebook PrestoDB -分布式 SQL 查询引擎。 Google BigQuery - Google 推出的一项 Web 服务，该服务让开发者可以使用 Google 的架构来运行 SQL 语句对超级大的数据库进行操作，是 Dremel 的实现。 PipelineDB - 一个开源的关系数据库，它可以在实时流数据上执行 SQL 查询，并将结果增量地存储在表中。 Pivotal HDB - Hadoop 上的类 SQL 数据仓库系统。/li> RainstorDB - 用于存储 PB 级结构化和半结构化数据量的数据库。 Spark Catalyst - Apache Spark 的查询优化框架。 SparkSQL - 使用 Spark 操作结构化的数据。 Splice Machine - 兼具了 SQL 和 NoSQL 的各自优势，且能对操作型和分析型应用进行实时处理，具有 ACID 特性。 Stinger - 由 Hortonworks 开发的一个彻底提升 Hive 效率的工具 Tajo - Hadoop 之上的分布式数据仓库系统。 Trafodion - 由惠普开发并开源的基于 Hadoop 平台的事务数据库引擎。提供了一个基于 Hadoop 平台的交易型 SQL 引擎，是一个擅长处理交易型负载的 Hadoop 大数据解决方案。 数据摄取 Amazon Kinesis - 一种在 AWS 上流式处理数据的平台,让您可以轻松地加载和分析流数据,同时还可让您根据具体需求来构建自定义流数据应用程序。 Amazon Web Services Glue - 一项完全托管的提取、转换和加载 (ETL) 服务，让用户能够轻松准备和加载数据进行分析。 Apache Chukwa - 数据采集系统。 Apache Flume - 一个分布式的、可靠的、易用的系统,可以有效地将来自很多不同源系统的大量日志数据收集、汇总或者转移到一个数据中心存储。 Apache Kafka - 分布式发布订阅消息系统。 Apache NiFi - 一个易用、强大、可靠的数据处理与分发系统 Apache Sqoop - 是一款开源的工具，主要用于在 Hadoop/Hive 与传统的数据库(Mysql、Oracle...)间进行数据的传递 Cloudera Morphlines - 帮助将 ETL 的数据加载到 Solr、HBase 或 Hadoop 中的框架。 Embulk - 开源的批量数据加载器，帮助在各种数据库、存储、文件格式和云服务之间传输数据。 Facebook Scribe - 流日志数据聚合器。 Fluentd - 用于收集事件和日志的工具。 Google Photon - 地理分布式系统，用于实时连接多个连续流动的数据流，具有高可伸缩性和低延迟。 Heka - 开源流处理系统。 HIHO - 用于将不同数据源的数据和 Hadoop 进行连接的框架。 Kestrel - 分布式消息队列系统。 LinkedIn Databus - LinkedIn 开源的一个低延迟、可靠的、支持事务的、保持一致性的数据变更抓取系统。 LinkedIn Kamikaze - 一种实用工具包，对 document lists 提供一系列的实现。 LinkedIn White Elephant - 一个 Hadoop 日志收集器和展示器，它提供了用户角度的Hadoop集群可视化。 Logstash - 一个开源的日志收集管理工具，可以采集来自不同数据源的数据,并对数据进行处理后输出到多种输出源。 Netflix Suro - Netflix 开源的一款工具，它能够在数据被发送到不同的数据平台(如Hadoop、Elasticsearch)之前，收集不同应用服务器上的事件数据。 Pinterest Secor - 实现 Kafka 日志持久性的服务 Linkedin Gobblin -一套分布式数据集成框架，旨在简化大数据集成工作当中的各类常见任务，具体包括数据流与批量生态系统的提取、复制、组织与生命周期管理。 Skizze - 一种概率数据结构服务和存储。 StreamSets Data Collector - 使用一个简单的 IDE 来连续大数据摄取基础设施。 Yahoo Pulsar - 由 Yahoo 开发并开源的一个企业级的发布订阅消息系统。 Alooma - 实时的数据管道服务，支持将 MySQL 等数据源的数据移动到数据仓库中。 服务编程 Akka Toolkit - 基于 Actor 模型，提供了一个用于构建可扩展的(Scalable)、弹性的(Resilient)、快速响应的(Responsive)应用程序的平台。 Apache Avro - 数据序列化系统。 Apache Curator - 为 Apache ZooKeeper 开发的类库。 Apache Karaf - Apache 旗下的一个开源项目，同时也是一个基于 OSGi 的运行环境，Karaf 提供了一个轻量级的 OSGi 容器,可以用于部署各种组件,应用程序。 Apache Thrift - Facebook 开源的跨语言的 RPC 通信框架 Apache Zookeeper - 一个分布式应用程序协调服务。 Google Chubby - 一个分布式锁服务，Chubby 底层一致性实现就是以 Paxos 为基础的 Hydrosphere Mist - 一个将 Apache Spark 分析任务和机器学习模型转换为实时、批处理或反应性 web 服务的服务。 Linkedin Norbert - 集群管理系统。 Mara - 一个轻量级的自定义ETL框架。 OpenMPI - 消息传递框架。 Serf - 去中心化的服务发现和编排解决方案。 Spotify Luigi - 用于构建批处理作业的复杂管道的 Python 包。它处理依赖项解析、工作流管理、可视化、处理故障、命令行集成等等。 Spring XD - 用于数据摄取、实时分析、批处理和数据导出的分布式和可扩展系统。 Twitter Elephant Bird - 用于处理 lzop 压缩数据的库。 Twitter Finagle - JVM的异步网络堆栈。 调度 Apache Airflow - Airbnb 开源的一个用 Python 编写的工作流管理平台。 Apache Aurora - 长期运行服务和计划作业的 Mesos 框架。 Apache Falcon - 数据管理框架。 Apache Oozie - 工作流作业调度器。 Azure Data Factory - 可大规模简化 ETL 的混合数据集成服务 Chronos - 分布式和容错调度器。 Linkedin Azkaban - 批处理工作流作业调度程序。 Schedoscope - 用于 Hadoop 作业的敏捷调度 Scala DSL。 Sparrow - 调度平台。 机器学习 Azure ML Studio - 基于云的 R、Python 机器学习平台。 brain - JavaScript 中的神经网络。 Cloudera Oryx - 实时大规模机器学习。 Concurrent Pattern - Cascading 上的机器学习框架。 convnetjs - Javascript 中的深入学习，可以在浏览器中训练卷积神经网络(或普通神经网络)。 DataVec - 一个用于 Java 和 Scala 深度学习的矢量化和数据预处理库。Deeplearning4j生态系统的一部分。 Deeplearning4j - 美国 AI 创业公司 Skymind 开源并维护的一个基于 Java/JVM 的深度学习框架，可使用CPU或GPU运行。 Decider - Ruby中灵活且可扩展的机器学习。 ENCOG - 支持多种高级算法的机器学习框架，以及支持规范化和处理数据的类。 etcML - 在线免费文本分析工具是由美国的斯坦福大学计算机教授开发的基于成熟的文本分析引擎 Etsy Conjecture - Scalding 中可扩展的机器学习。 Feast - 用于管理、发现和访问机器学习特性的特性存储库。Feast 为模型训练和模型服务提供了一致的特征数据视图。 GraphLab Create - Python 中的机器学习平台，包含大量 ML 工具包、数据工程和部署工具。 H2O - 使用 Hadoop、R 和 Python 进行统计、机器学习和数学运行时。 Keras - 一个高层神经网络API，Keras 由纯 Python 编写而成并基 Tensorflow、Theano 以及 CNTK 后端。受 Torch 启发。 Lambdo 是一个工作流引擎，通过将一个分析管道(i)特征工程和机器学习(ii)模型训练和预测(iii)结合起来，通过用户定义(Python)函数实现表填充和列评估，大大简化了数据处理和分析。 Mahout - 是 Apache Software Foundation(ASF) 旗下的一个开源项目,提供一些可扩展的机器学习领域经典算法的实现,旨在帮助开发人员更加方便快捷地创建智能应用程序。 MLbase - 是Spark生态圈的一部分,专注于机器学习,包含三个组件:MLlib、MLI、ML Optimizer。 MLPNeuralNet - 一个针对 iOS 和 Mac OS 系统的快速多层感知神经网络库，可通过已训练的神经网络预测新实例。 MOA - 实时进行大数据流挖掘和大规模机器学习。 MonkeyLearn - 让文本挖掘变得很容易，可以从文本中提取和分类数据。 ND4J - JVM 的矩阵库，可以认为是 Java 中的 Numpy。 nupic - 一个实现了HTM学习算法的机器智能平台。 PredictionIO - 面向开发人员和数据科学家的开源机器学习服务，构建在 Hadoop, Mahout 和 Cascading 之上。 RL4J - 一个与 Deeplearning4j 集成的强化学习框架 SAMOA - 分布式流数据机器学习框架。 scikit-learn - 专门面向机器学习的 Python 开源框架，实现了各种成熟的算法。 Spark MLlib - 使用 Spark 实现一些常见的机器学习算法和实用程序,包括分类、回归、聚类、协同过滤、降维以及底层优化, Sibyl - 谷歌大型机器学习系统. TensorFlow - 一个采用数据流图(data flow graphs)，用于数值计算的开源软件库。 Theano - 蒙特利尔大学支持的以 Python 为核心的机器学习类库。 Torch - 是一个基于 BSD License 的开源的机器学习的框架 Velox - 服务于机器学习预测的系统。 Vowpal Wabbit - 由微软和雅虎赞助的学习系统。 WEKA - 一套机器学习软件。 BidMach - CPU 和 GPU 加速库的机器学习库。 Benchmarking Apache Hadoop Benchmarking - 测试 Hadoop 性能的微基准测试。 Berkeley SWIM Benchmark - 真实大数据工作负载基准。 Intel HiBench - Hadoop 基准套件。 PUMA Benchmarking - MapReduce 应用程序的基准测试套件。 Yahoo Gridmix3 - 来自 Yahoo 工程师团队的 Hadoop 集群基准测试。 Deeplearning4j Benchmarks 安全 Apache Ranger - 是一个用在 Hadoop 平台上并提供操作、监控、管理综合数据安全的框架。 Apache Eagle -由 eBay 公司开源的一个识别大数据平台上的安全和性能问题的开源解决方案。 Apache Knox Gateway - Hadoop 集群中用于数据处理的 REST API 网关 Apache Sentry - 为 Hadoop 集群中的元数据和数据存储提供集中、细粒度的访问控制。 BDA - Hadoop 和 Spark 的漏洞检测器 系统部署 Apache Ambari - 一个集中部署、管理、监控Hadoop 分布式集群的工具。 Apache Bigtop - 一个针对基础设施工程师和数据科学家的开源项目，旨在全面打包、测试和配置领先的开源大数据组件/项目，包括但不限于 Hadoop、HBase 和 Spark 。 Apache Helix - 集群管理框架。 Apache Mesos - 一个类似于 YARN 的集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享，可以运行 Hadoop、MPI、Hypertable、Spark。 Apache Slider - 是一个 YARN 应用程序，用于在 YARN 上部署现有的分布式应用程序。 Apache Whirr - 运行云服务的一组 Java 类库。 Apache YARN - 集群管理系统。 Brooklyn - 简化应用程序部署和管理的库。 Buildoop - 类似于 Apache BigTop，基于 Groovy 语言开发。 Cloudera HUE - 用于与 Hadoop 交互的 web 应用程序。 Facebook Prism - 多数据中心复制系统。 Google Borg - Google 的内部大型集群管理系统。 Google Omega - Google 内部第三代的集群管理框架。 Hortonworks HOYA - 可以在 YARN 上部署 HBase 集群的应用程序。 Kubernetes - Google 团队发起并维护的基于 Docker 的开源容器集群管理系统。 Marathon - 一个 Mesos 框架，能够支持运行长服务。 应用程序 411 - 一个警报管理Web应用程序。 Adobe spindle - 使用 Scala、Spark 和 Parquet 进行 web 分析的下一代系统。 Apache Kiji - 基于 HBase 的实时数据采集与分析框架。 Apache Metron - 一种多功能的安全遥测数据捕获、流分析和威胁响应平台，代表了安全数据平台的最新发展水平。 Apache Nutch - 开源 web 爬虫程序。 Apache OODT - NASA 开源的用于做数据管理的系统。 Apache Tika - 使用 Java 编写的内容检测和分析框架。 Argus - 时序监控报警平台。 AthenaX - 一个流分析平台，允许用户使用结构化查询语言(SQL)运行生产质量的大规模流分析。 Atlas - 用于管理维度时间序列数据的系统。 Countly - 基于 Node.js 和 MongoDB 的开源移动和 web 分析平台。 Domino - 运行、扩展、共享和部署模型——不需要任何基础设施。 Eclipse BIRT - 基于 Eclipse 的报告系统。 ElastAert - 为 ES 打造的报警监控工具。 Eventhub - 开源事件分析平台。 Hermes - 构建在 Kafka 之上的异步消息代理。 HIPI Library - 使用 Hadoop 的 MapReduce 来执行图像处理任务的API。 Hunk - Hadoop 的分析工具。 Imhotep - 大型分析平台。 Jupyter - 基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。 MADlib - RDBMS 的数据处理库，用于分析数据。 Kapacitor - 用于对时间序列数据进行处理、监视和警报的开源框架。 Kylin - 一个开源的分布式分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay Inc. 开发并贡献至开源社区，能在亚秒内查询巨大的Hive表。 PivotalR - 支持在 Pivotal HD / HAWQ 以及 PostgreSQL 上运行 R。 Rakam - 开源实时自定义分析平台，由 Postgresql, Kinesis 和 PrestoDB 提供支持。 Qubole - 能够自动扩展 Hadoop 集群以及内置的链接器。 Sense - 数据科学和大数据分析的云平台。 SnappyData - 一个统一 OLTP+OLAP +流式写入的内存分布式数据库。 Snowplow - 由 Hadoop，Kinesis，Redshift 和 Postgres 支持的企业级 Web 和事件分析。 SparkR - 用于 Spark 的 R 前端。 Splunk - 一款成熟的商业化日志处理分析产品。 Sumo Logic - 基于云的日志处理分析产品。 Talend - YARN、Hadoop、HBASE、Hive、HCatalog 和 Pig 的统一开源环境。 Warp - 大数据示例查询工具(OS X 应用) 搜索引擎和框架 Apache Lucene - 一套用于全文检索和搜索的开放源码程序库 Apache Solr - 是 Apache Lucene 项目的开源企业搜索平台。其主要功能包括全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及富文本（如Word、PDF）的处理。 Elassandra - 是 ElasticSearch 的一个分支，经过修改，可以作为 Apache Cassandra 的插件运行，具有可扩展和灵活的点对点架构。 ElasticSearch - 一个基于 Lucene 库的搜索引擎。它提供了一个分布式、支持多租户的全文搜索引擎，具有 HTTP Web 接口和无模式 JSON 文档。 http://Enigma.io – 免费增值的 Web 应用程序，用于对 Web 上抓取的海量数据集进行浏览，过滤，分析，搜索和导出。 Facebook Unicorn - 社交图搜索平台. Google Caffeine - 一个高性能、出色的缓存类库。 Google Percolator - 由 Google 公司开发的、为大数据集群进行增量处理更新的系统，主要用于 google 网页搜索索引服务。 TeraGoogle - 大型搜索索引。 HBase Coprocessor - HBase 的协处理器，Percolator 的实现。 Lily HBase Indexer - 一款快速、简单的 HBase 的内容检索方案，它可以帮助你在 Solr 中建立 HBase 的数据索引，从而通过 Solr 进行数据检索。 LinkedIn Bobo - 完全用 Java 编写的 Faceted Search 实现，是 Apache Lucene 的扩展。 LinkedIn Cleo -一个灵活的软件库，用于处理一些预输入和自动完成的搜索功能。 LinkedIn Galene - LinkedIn 的搜索架构。 LinkedIn Zoie - 一个用 Java 编写的实时搜索/索引系统。 MG4J - MG4J (Managing Gigabytes for Java) 是一个用 Java 编写的大型文档集合的全文搜索引擎，它是高度可定制的，高性能的，并提供了最先进的功能和新的研究算法。 Sphinx Search Server - 全文搜索引擎。 Vespa - 在大型数据集上进行低延迟计算的引擎。它存储和索引数据，以便可以在服务时执行对数据的查询，选择和处理。 MySQL 分支和演进 Amazon RDS - AWS 的 MySQL 数据库。 Drizzle - MySQL 6.0的演进。 Google Cloud SQL - Google 云中的 MySQL 数据库。 MariaDB - MySQL 的一个分支，采用GPL授权许可。目的是完全兼容 MySQL，包括 API 和命令行。 MySQL Cluster - 使用 NDB 集群存储引擎实现 MySQL 集群。 Percona Server - MySQL 增强版，可以替代它。 ProxySQL - MySQL 的高性能代理。 TokuDB - TokuDB 是 MySQL 和 MariaDB 的存储引擎。 WebScaleSQL - WebScaleSQL 是 Facebook、 Google、Twitter 和 Linkedin 四家公司的MySQL 团队发起的 MySQL 开源组织，旨在改进 MySQL 在规模和性能等方面的问题。 PostgreSQL 分支和演进 HadoopDB - MapReduce 和 DBMS 的混合体。 IBM Netezza - 高性能数据仓库设备。 Postgres-XL - 可伸缩的基于 PostgreSQL 的开源数据库集群。 RecDB - 完全在 PostgreSQL 内部构建的开源推荐引擎。 Stado - 仅针对数据仓库和数据集市应用程序的开源 MPP 数据库系统。 Yahoo Everest - 由 PostgreSQL 派生的 PB 级数据库/MPP。 TimescaleDB - 针对快速摄取和复杂查询而优化的开源时间序列数据库。 PipelineDB - 开源的流式数据库，基于 PostgreSQL 数据库改造的，允许我们通过 SQL 的方式，对数据流做操作，并把操作结果储存起来。 Memcached 分支和演进 Facebook McDipper - 用于闪存的键/值缓存，设计目的在于提高闪存存储的使用效率。 Facebook Memcached - Memcache 的分支。 Twemproxy - 一个快速、轻量级的 memcached 和 redis 代理。 Twitter Fatcache - 用于闪存的键/值缓存。 Twitter Twemcache - Memcache 的分支。 嵌入式数据库 Actian PSQL - 由 Pervasive Software 开发的符合 ACID 的 DBMS，针对嵌入应用程序进行了优化。 BerkeleyDB - 可为键/值数据提供高性能的嵌入式数据库。 HanoiDB - Erlang LSM BTree 存储。 LevelDB - Google 开源的持久化KV单机数据库，具有很高的随机写，顺序读/写性能。 LMDB - 由 Symas 开发的基于 Btree-based 的高性能 mmap key-value 数据库 RocksDB - Facebook 公司基于 LevelDB 开发的一款开源嵌入式数据库引擎。 商业智能 BIME Analytics - 商业智能云平台。 Blazer - 使商业智能变得简单。 Chartio - 商业智能平台，可以可视化和浏览我们的数据。 datapine - 自助式商业智能工具。 GoodData - 商业智能和大数据分析软件。 Jaspersoft - 强大的商业智能套件。 Jedox Palo - 可定制的商业智能平台. Jethrodata - 交互式大数据分析。 Metabase - 一个简单、开源的方式，通过给公司成员提问，从得到的数据中进行分析、学习。 Microsoft - 商业智能软件及平台。 Microstrategy - 用于商业智能、移动智能和网络应用程序的软件平台。 Numeracy - SQL 客户端和商业智能。 Pentaho - 商业智能平台。 Qlik - 商业智能及分析平台。 Redash - 开源商业智能平台，支持多个数据源和计划查询。 Saiku - 开源分析平台。 SpagoBI - 开源商业智能平台。 SparklineData SNAP - 基于 Apache Spark 的商业智能平台。 Tableau - 商业智能平台。 Zoomdata - 大数据分析平台。 数据可视化 Airpal - PrestoDB 的 Web UI。 AnyChart - 一套灵活的 JavaScript (HTML5) 库，可满足您的所有数据可视化需求。 Arbor - 一个使用 web workers 和 jQuery 创建的图可视化库。 Banana - 可视化存储在 Solr 中的日志和带时间戳的数据，是 Kibana 的一部分。 Bloomery - Impala 的 Web UI。 Bokeh - 一个 Python 交互式可视化库，支持现代化 Web 浏览器，提供非常完美的展示功能。 C3 - 基于 D3 的可重用图表库 CartoDB - 开源的云上地理空间数据库，允许存储和可视化 web 上的数据。使用 CartoDB 可以快速创建基于地图的可视化效果。 chartd - 响应式、视网膜兼容图表，仅需要一个 img 标签。 Chart.js - 一套开源、简单、干净并且有吸引力的基于 HTML5 技术的 JavaScript 图表工具。 Chartist.js - 非常简单而且实用的 JavaScript 前端图表生成器。 Crossfilter - 一个 JavaScript 库，用于在 JavaScript 中制作交互式的仪表板，可以与 dc.js 、d3.js 一起工作。 Cubism - 用于时间序列可视化的 JavaScript 库。 Cytoscape - 一个专注于网络可视化和分析的开源软件。 DC.js - 一个用于网页作图、生成互动图形的 JavaScript 函数库。 D3 - 目前最流行的数据可视化库之一，小型，灵活，高效的数据可视化库，用来创建和操作基于数据的交互式文档。 D3.compose - 由可重复使用的图表和组件组成复杂的、数据驱动的可视化文件。 D3Plus - d3.js 的一组相当强大的可重用图表和样式。 DevExtreme React Chart - 基于高性能插件的 React 图表，用于 Bootstrap 和 Material Design。 Echarts - 一款由百度前端技术部开发的，基于Javascript 的数据可视化图表库，提供直观，生动，可交互，可个性化定制的数据可视化图表。 Envisionjs - 一个基于 HTML5 技术的数据可视化库 FnordMetric - 一个开源的 Web 应用，可用于创建实时仪表板，方便可视化任何数据。 Frappe Charts - 一个受 Github 启发的轻量级 SVG 图表库，它不依赖任何类库和框架。 Freeboard - 让用户创建他们自己的用来监控物联网部署的仪表盘，该代码在 GitHub上免费提供，你可以通过这些仪表板展示跟踪空气质量、住宅电器、酿酒情况和实时环境条件变化。 Gephi - 一款开源免费跨平台基于 JVM 的网络分析领域的数据可视化处理软件 Google Charts - 一种交互式 Web 服务，可根据用户提供的数据创建图形图表 Grafana - 一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。 Graphite - 一款开源的监控绘图工具。 Highcharts - 兼容 IE6+、完美支持移动端、图表类型丰富、方便快捷的 HTML5 交互性图表库。 IPython - 一种基于 Python 的交互式解释器。相较于原生的 Python Shell，IPython 提供了更为强大的编辑和交互功能。 Kibana - Elasticsearch 的开源数据可视化插件。 Lumify - 开源大数据分析可视化平台。 Matplotlib - Python 编程语言及其数值数学扩展包 NumPy 的可视化操作界面。 Metricsgraphic.js - 一个建立在 D3 基础上，为可视化和时间序列化的数据而优化的库。 NVD3 - d3.js 的图表组件。 Peity - 渐进式 SVG 条形图，折线图和饼图。 http://Plot.ly - Plotly 为个人和协作提供在线图形，分析和统计工具，以及 Python，R，MATLAB，Perl，Julia，Arduino 和 REST 的科学图形库。 Plotly.js 一个开源的交互式 JavaScript 图形库，建立在 d3.js 和 webgl 之上，并支持 20 多种类型的交互式图表。 Recline - 简单而强大的库，可以使用纯 Javascript 和 HTML 构建数据应用程序。 Redash - 查询和可视化数据的开源平台。 ReCharts - 一个基于React组件的可组合图表库。 Shiny - R 的 Web 应用程序框架。 Sigma.js - 专门用于图形绘制的 JavaScript 库。 Superset - 由 Airbnb 开发并开源一个数据探索和可视化平台，设计用来提供直观的，可视化的，交互式的分析体验。 Vega - 一个可视化的语法。 Zeppelin - 一个基于 Web 的 notebook，提供交互数据分析和可视化。 Zing Charts - 一个功能强大的 JavaScript 图表。 物联网和传感器数据 Apache Edgent (Incubating) - 一种编程模型和具有微内核风格的运行时，可嵌入到网关和小型的物联网设备中。 Azure IoT Hub - 托管服务，支持 IoT 设备与 Azure 之间的双向通信。 TempoIQ - 基于云计算的传感器分析。. 2lemetry - 物联网平台。 Pubnub - 数据流网络。 ThingWorx - 可用于查找数据来源，使数据与情境相关，合成数据，同时协调流程，以提供强大的Web、移动和AR 体验的平台。 IFTTT - 一个新生的网络服务平台，通过其他不同平台的条件来决定是否执行下一条命令。 Evrything- 使产品智能化。 NetLytics - 用于在Spark上处理网络数据的分析平台。 有趣的阅读材料 Big Data Benchmark - Redshift，Hive，Shark，Impala 和 Stiger/Tez的基准。 NoSQL Comparison - Cassandra，MongoDB，CouchDB，Redis，Riak，HBase，Couchbase，Neo4j，Hypertable，ElasticSearch，Accumulo，VoltDB 和 Scalaris 的比较。 Monitoring Kafka performance - 监视 Apache Kafka 的指南，包括度量收集的本地方法。 Monitoring Hadoop performance - 监视 Hadoop 的指南，概述了 Hadoop 体系结构以及度量收集的本机方法。 Monitoring Cassandra performance - 监控 Cassandra 的指南，包括度量收集的本地方法。 "},"part3/spark/yarn_model.html":{"url":"part3/spark/yarn_model.html","title":"YARN的两种运行模式","keywords":"","body":"YARN的两种运行模式 yarn-client模式 yarn-cluster模式 资料 YARN的两种运行模式 使用yarn集群的Spark两种运行模式简介 "},"part3/spark/spark_principle.html":{"url":"part3/spark/spark_principle.html","title":"Spark架构和工作原理","keywords":"","body":"Spark架构和工作原理 资料 Spark架构和工作原理、RDD依赖关系、DAG、stage详解 Spark基本架构及原理 Spark DAG 概述 "},"part3/spark/pyspark_production.html":{"url":"part3/spark/pyspark_production.html","title":"编写生产级 PySpark 作业的最佳实践","keywords":"","body":"编写生产级 PySpark 作业的最佳实践 资料 Best Practices Writing Production-Grade PySpark Jobs ekampf/PySpark-Boilerplate 说明 详细的教程就不说了，看英文文档。目前已经运行了几年，团队开发和维护都比较方便。 目录： jobs文件夹，可以多级目录，调用的时候，参数里面--job里面写的值就例如这样test.wordcount，标示不同级别的目录。 编译上线 # 安装项目所依赖的包 pip install -U -r requirements.txt -t ./src/libs # 开始打包上线，最后就是`main.py`, `jobs.zip`, `libs.zip`放到服务器上面就可以运行了。 mkdir ./dist cp ./src/main.py ./dist cd ./src && zip -x main.py -x \\*libs\\* -r ../dist/jobs.zip . cd ./src/libs && zip -r ../../dist/libs.zip . "},"part3/hive_default_fileformat.html":{"url":"part3/hive_default_fileformat.html","title":"hive默认建表存储格式","keywords":"","body":"hive默认建表存储格式 默认值与可选值 hive.default.fileformat 默认值: TextFile 可选值：TextFile，SequenceFile，RCfile，ORC，Parquet spark-sql测试 --hiveconf ## 1.进入spark-sql spark-sql --hiveconf hive.default.fileformat=parquet ## 2.创建表并插入数据 create table hudi.person2(id bigint,name string); insert into table hudi.person2 values(1,'zs'),(2,'ls'); select * from hudi.person2 limit 10; ## 3.确认建表格式是否为parquet，存储格式是否显示 show create table hudi.person2; ## 4.查看hdfs目录确认文件结构 spark-sql测试 set ## 1.进入spark-sql spark-sql ## 2.设置默认存储格式为 Parquet set hive.default.fileformat=parquet; ## 开启压缩 set spark.sql.parquet.compression.codec=gzip; ## 3.创建表并插入数据 create table hudi.person3(id bigint,name string,job string); insert into table hudi.person3 values(1,'zs,aa分隔符:^_^','doctor'),(2,'ls','migrant workers'); select id,job from hudi.person3 limit 10; ## 4.确认建表格式是否为parquet，存储格式是否显示 show create table hudi.person3; ## 5.查看hdfs目录确认文件结构 关于spark存储格式与压缩的设置 ORC 1.建表时在TBLPROPERTIES中增加属性\"orc.compress\"=\"snappy\"，需要对每张表进行设置 2.设置hive参数hive.exec.orc.default.compress=snappy，针对hive全局设置的，比较方便 Parquet，Hive Parquet默认不采用压缩算法 1.建表时在TBLPROPERTIES中增加属性\"orc.compress\"=\"snappy\"，需要对每张表进行设置 2.spark内执行-- 优先级从上往下，通常只用第一个 set spark.sql.parquet.compression.codec=gzip; set parquet.compression=snappy; set compression=gzip; 知识点 列式存储 相对于关系数据库中通常使用的行式存储，在使用列式存储时每一列的所有元素都是顺序存储的。由此特点可以给查询带来如下的优化： 查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推。 由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O。 由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效。 Parquet存储格式 Apache Parquet是Hadoop生态圈中一种新型列式存储格式，它可以兼容Hadoop生态圈中大多数计算框架(Mapreduce、Spark等)，被多种查询引擎支持（Hive、Impala、Drill等），并且它是语言和平台无关的。 文件结构 Parquet文件是以二进制方式存储的，是不可以直接读取和修改的，Parquet文件是自解析的，文件中包括该文件的数据和元数据。在HDFS文件系统和Parquet文件中存在如下几个概念： HDFS块(Block)：它是HDFS上的最小的副本单位，HDFS会把一个Block存储在本地的一个文件并且维护分散在不同的机器上的多个副本，通常情况下一个Block的大小为256M、512M等。 HDFS文件(File)：一个HDFS的文件，包括数据和元数据，数据分散存储在多个Block中。 行组(Row Group)：按照行将数据物理上划分为多个单元，每一个行组包含一定的行数，在一个HDFS文件中至少存储一个行组，Parquet读写的时候会将整个行组缓存在内存中，所以如果每一个行组的大小是由内存大的小决定的。 列块(Column Chunk)：在一个行组中每一列保存在一个列块中，行组中的所有列连续的存储在这个行组文件中。不同的列块可能使用不同的算法进行压缩。 页(Page)：每一个列块划分为多个页，一个页是最小的编码的单位，在同一个列块的不同页可能使用不同的编码方式。 通常情况下，在存储Parquet数据的时候会按照HDFS的Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式如下图所示。 上图展示了一个Parquet文件的结构，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length存储了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和当前文件的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三种类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页，但是在后面的版本中增加。 ORC文件格式 ORC文件格式是一种Hadoop生态圈中的列式存储格式，它的产生早在2013年初，最初产生自Apache Hive，用于降低Hadoop数据存储空间和加速Hive查询速度。和Parquet类似，它并不是一个单纯的列式存储格式，仍然是首先根据行组分割整个表，在每一个行组内进行按列存储。ORC文件是自描述的，它的元数据使用Protocol Buffers序列化，并且文件中的数据尽可能的压缩以降低存储空间的消耗，目前也被Spark SQL、Presto等查询引擎支持，但是Impala对于ORC目前没有支持，仍然使用Parquet作为主要的列式存储格式。2015年ORC项目被Apache项目基金会提升为Apache顶级项目。 文件结构 和Parquet类似，ORC文件也是以二进制方式存储的，所以是不可以直接读取，ORC文件也是自解析的，它包含许多的元数据，这些元数据都是同构ProtoBuffer进行序列化的。ORC的文件结构入图6，其中涉及到如下的概念： ORC文件：保存在文件系统上的普通二进制文件，一个ORC文件中可以包含多个stripe，每一个stripe包含多条记录，这些记录按照列进行独立存储，对应到Parquet中的row group的概念。 文件级元数据：包括文件的描述信息PostScript、文件meta信息（包括整个文件的统计信息）、所有stripe的信息和文件schema信息。 stripe：一组行形成一个stripe，每次读取文件是以行组为单位的，一般为HDFS的块大小，保存了每一列的索引和数据。 stripe元数据：保存stripe的位置、每一个列的在该stripe的统计信息以及所有的stream类型和位置。 row group：索引的最小单位，一个stripe中包含多个row group，默认为10000个值组成。 stream：一个stream表示文件中一段有效的数据，包括索引和数据两类。索引stream保存每一个row group的位置和统计信息，数据stream包括多种类型的数据，具体需要哪几种是由该列类型和编码方式决定。 在ORC文件中保存了三个层级的统计信息，分别为文件级别、stripe级别和row group级别的，他们都可以用来根据Search ARGuments（谓词下推条件）判断是否可以跳过某些数据，在统计信息中都包含成员数和是否有null值，并且对于不同类型的数据设置一些特定的统计信息。 引用处 Parquet与ORC：高性能列式存储格式 "},"part3/auto/gitea_jenkins.html":{"url":"part3/auto/gitea_jenkins.html","title":"gitea + Jenkins自动化部署项目","keywords":"","body":"gitea + Jenkins自动化部署项目 gitea 和 gitlab选型 gitea 只是 git 的操作库实现搭配了基础 wiki 这些功能，需要配合其他第三方库或工具才能提供更专业的支持。比如 cicd 要 drone。Gitea 功能比较简单，看你们的需求如果只是单纯存存代码，只做 CI/CD 是足够的，很多附加功能处于缺失状态，需要大量依赖第三方工具。 Gitlab 是完整的 git 集成环境，包含 npm，nuget，docker registry 等私有集成，还有完整的 CI/CD，k8s 集成方案。Gitlab 需要的机器最低配置比较高，对应的，功能也多了很多，如果需要代码 Review 、重度使用 issue 功能、使用 Gitlab 管理项目就比较合适。 决定性因素：对于计算机资源的占用，gitlab明显就是一直超级怪兽，而我的truenas系统只有32g，选择小型化又满足基本功能的gitea就可以了。 Jenkins自动化部署 好处：自动化，开发者push代码之后，全自动编译，打包项目文件上传到服务器指定位置，避免人为出错。 坏处：看项目大小，这个还是比较占用计算机资源，限制好内存大小。花点时间学习一下。 Jenkins发布到服务器的时候设置 说明： source files 就是准备上传的文件，该文件是相对于这个项目的workspace目录，也就是$JENKINS_HOME/workspace/xxxx/ 每个项目都会在build时候自动创建worksapce 比如我要上传 $JENKINS_HOME/workspace/xxxx/target/class/helloworld1.java $JENKINS_HOME/workspace/xxxx/target/class/helloworld2.java 那么我们就可以设置如下参数 source files=target/class/*.java remove prefix = target (remove prefix必须是source files中指定的目录，如果不写，那就是把这个目录层级都上传，如果写target，就传class目录层级，如果写target/class 就传*.java文件) remote diretory = rd (remote diretory就是相对于系统配置中对服务器配置中的remote diretory来说的，比如在服务器配置中的remote diretory如果是空，那应该就是家目录，如果不是空，假如是/usr/local) 那这样上传过去，文件存在服务器的目录是 /usr/local/rd/class/*.java 也就是 服务器配置里的remote diretory[/usr/local]+这里配置的remote diretory[rd]+source files去掉remove prefix的目录剩下的部分[class/*.java] 资料 https://blog.csdn.net/tianmingqing0806/article/details/125408239 https://www.cnblogs.com/yxhblogs/p/14056752.html https://codeantenna.com/a/wcYUhntuqP https://juejin.cn/post/6844903813120262158 "}}